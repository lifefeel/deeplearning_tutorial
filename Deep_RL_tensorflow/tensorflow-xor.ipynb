{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 튜토리얼\n",
    "## 소개\n",
    "텐서플로우(TensorFlow)는 기계 학습과 딥러닝을 위해 구글에서 만든 오픈소스 라이브러리입니다. 데이터 플로우 그래프(Data Flow Graph) 방식을 사용하였습니다.\n",
    "\n",
    "### 데이터 플로우 그래프\n",
    "\n",
    "데이터 플로우 그래프는 수학 계산과 데이터의 흐름을 노드(Node)와 엣지(Edge)를 사용한 방향 그래프(Directed Graph)로 표현합니다.\n",
    "\n",
    "![data flow graph](https://www.tensorflow.org/images/tensors_flowing.gif)\n",
    "\n",
    "노드는 수학적 계산, 데이터 입/출력, 그리고 데이터의 읽기/저장 등의 작업을 수행합니다. 엣지는 노드들 간 데이터의 입출력 관계를 나타냅니다.\n",
    "\n",
    "엣지는 동적 사이즈의 다차원 데이터 배열(=텐서)을 실어나르는데, 여기에서 텐서플로우라는 이름이 지어졌습니다.\n",
    "\n",
    "> 텐서(Tensor)는 과학과 공학 등 다양한 분야에서 이전부터 쓰이던 개념입니다. 수학에서는 [임의의 기하 구조를 좌표 독립적으로 표현](http://ghebook.blogspot.kr/2011/06/tensor.html)하기 위한 표기법으로 알려져 있지만, 분야마다 조금씩 다른 의미로 사용됩니다. 여기에서는 *학습 데이터가 저장되는 다차원 배열* 정도로 이해하시면 되겠습니다.\n",
    "\n",
    "### 특징\n",
    "\n",
    "텐서플로우는 다음과 같은 특징을 가집니다:\n",
    "\n",
    "- 데이터 플로우 그래프를 통한 풍부한 표현력\n",
    "- 코드 수정 없이 CPU/GPU 모드로 동작\n",
    "- 아이디어 테스트에서 서비스 단계까지 이용 가능\n",
    "- 계산 구조와 목표 함수만 정의하면 자동으로 미분 계산을 처리 \n",
    "- Python/C++를 지원하며, [SWIG](http://www.swig.org)를 통해 다양한 언어 지원 가능\n",
    "\n",
    "*이후의 설명은 [Python](https://www.python.org)을 중심으로 진행하겠습니다.* (pip를 통한 Python3설치는 개발 중으로, Python2 기반으로 하겠습니다.)\n",
    "\n",
    "> *\"구글이 텐서플로우를 오픈소스로 한 것은, 기계 학습이 앞으로 제품과 기술을 혁신하는데 가장 필수적인 요소라고 믿기 때문입니다.\"      - Google Brain Team*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 개념 익히기\n",
    "\n",
    "일단 기본 용어부터 살펴보겠습니다.\n",
    "\n",
    "### 용어\n",
    "#### 오퍼레이션(Operation)\n",
    "그래프 상의 노드는 오퍼레이션(줄임말 *op*)으로 불립니다. 오퍼레이션은 하나 이상의 *텐서*를 받을 수 있습니다. 오퍼레이션은 계산을 수행하고, 결과를 하나 이상의 텐서로 반환할 수 있습니다.\n",
    "\n",
    "#### 텐서(Tensor)\n",
    "내부적으로 모든 데이터는 텐서를 통해 표현됩니다. 텐서는 일종의 다차원 배열인데, 그래프 내의 오퍼레이션 간에는 텐서만이 전달됩니다. ([Caffe](http://caffe.berkeleyvision.org)의 [Blob](http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html)과 유사합니다.)\n",
    "\n",
    "#### 세션(Session)\n",
    "\n",
    "그래프를 실행하기 위해서는 [세션](https://www.tensorflow.org/versions/master/api_docs/python/client.html#session-management) 객체가 필요합니다. 세션은 오퍼레이션의 실행 환경을 캡슐화한 것입니다.\n",
    "\n",
    "#### 변수(Variables)\n",
    "[변수](https://www.tensorflow.org/versions/master/how_tos/variables/index.html)는 그래프의 실행시, 패러미터를 저장하고 갱신하는데 사용됩니다. 메모리 상에서 텐서를 저장하는 버퍼 역할을 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-layer perceptron으로 XOR구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "0 0.694017 [[ 0.11375573]\n",
      " [ 0.00809596]]\n",
      "Accuracy: 0.25\n",
      "200 0.693612 [[ 0.08849787]\n",
      " [-0.00475294]]\n",
      "Accuracy: 0.25\n",
      "400 0.693408 [[ 0.06992097]\n",
      " [-0.01237414]]\n",
      "Accuracy: 0.25\n",
      "600 0.693303 [[ 0.05608314]\n",
      " [-0.0165417 ]]\n",
      "Accuracy: 0.25\n",
      "800 0.693246 [[ 0.0456293 ]\n",
      " [-0.01846074]]\n",
      "Accuracy: 0.25\n",
      "1000 0.693213 [[ 0.03761235]\n",
      " [-0.0189455 ]]\n",
      "Accuracy: 0.25\n",
      "1200 0.693194 [[ 0.03136802]\n",
      " [-0.01854263]]\n",
      "Accuracy: 0.25\n",
      "1400 0.693181 [[ 0.02642819]\n",
      " [-0.01761637]]\n",
      "Accuracy: 0.25\n",
      "1600 0.693173 [[ 0.02246104]\n",
      " [-0.01640683]]\n",
      "Accuracy: 0.25\n",
      "1800 0.693166 [[ 0.01922956]\n",
      " [-0.01507   ]]\n",
      "Accuracy: 0.25\n",
      "2000 0.693162 [[ 0.016563  ]\n",
      " [-0.01370516]]\n",
      "Accuracy: 0.25\n",
      "2200 0.693159 [[ 0.01433702]\n",
      " [-0.01237355]]\n",
      "Accuracy: 0.25\n",
      "2400 0.693156 [[ 0.01246006]\n",
      " [-0.01111106]]\n",
      "Accuracy: 0.25\n",
      "2600 0.693154 [[ 0.01086374]\n",
      " [-0.00993692]]\n",
      "Accuracy: 0.25\n",
      "2800 0.693152 [[ 0.00949629]\n",
      " [-0.00885951]]\n",
      "Accuracy: 0.25\n",
      "3000 0.693151 [[ 0.0083179 ]\n",
      " [-0.00788041]]\n",
      "Accuracy: 0.25\n",
      "3200 0.69315 [[ 0.00729749]\n",
      " [-0.00699691]]\n",
      "Accuracy: 0.25\n",
      "3400 0.69315 [[ 0.0064104 ]\n",
      " [-0.00620387]]\n",
      "Accuracy: 0.25\n",
      "3600 0.693149 [[ 0.00563676]\n",
      " [-0.00549486]]\n",
      "Accuracy: 0.25\n",
      "3800 0.693149 [[ 0.00496037]\n",
      " [-0.00486287]]\n",
      "Accuracy: 0.25\n",
      "4000 0.693148 [[ 0.00436782]\n",
      " [-0.00430083]]\n",
      "Accuracy: 0.25\n",
      "4200 0.693148 [[ 0.00384789]\n",
      " [-0.00380186]]\n",
      "Accuracy: 0.25\n",
      "4400 0.693148 [[ 0.00339112]\n",
      " [-0.00335949]]\n",
      "Accuracy: 0.25\n",
      "4600 0.693148 [[ 0.00298945]\n",
      " [-0.00296771]]\n",
      "Accuracy: 0.25\n",
      "4800 0.693148 [[ 0.00263595]\n",
      " [-0.00262102]]\n",
      "Accuracy: 0.25\n",
      "5000 0.693148 [[ 0.00232467]\n",
      " [-0.0023144 ]]\n",
      "Accuracy: 0.25\n",
      "5200 0.693147 [[ 0.00205043]\n",
      " [-0.00204337]]\n",
      "Accuracy: 0.25\n",
      "5400 0.693147 [[ 0.00180874]\n",
      " [-0.00180389]]\n",
      "Accuracy: 0.25\n",
      "5600 0.693147 [[ 0.00159567]\n",
      " [-0.00159234]]\n",
      "Accuracy: 0.25\n",
      "5800 0.693147 [[ 0.0014078]\n",
      " [-0.0014055]]\n",
      "Accuracy: 0.25\n",
      "6000 0.693147 [[ 0.00124211]\n",
      " [-0.00124051]]\n",
      "Accuracy: 0.25\n",
      "6200 0.693147 [[ 0.00109595]\n",
      " [-0.00109487]]\n",
      "Accuracy: 0.25\n",
      "6400 0.693147 [[ 0.00096704]\n",
      " [-0.00096628]]\n",
      "Accuracy: 0.25\n",
      "6600 0.693147 [[ 0.0008533 ]\n",
      " [-0.00085277]]\n",
      "Accuracy: 0.25\n",
      "6800 0.693147 [[ 0.00075297]\n",
      " [-0.00075258]]\n",
      "Accuracy: 0.25\n",
      "7000 0.693147 [[ 0.00066445]\n",
      " [-0.00066414]]\n",
      "Accuracy: 0.25\n",
      "7200 0.693147 [[ 0.00058634]\n",
      " [-0.00058609]]\n",
      "Accuracy: 0.25\n",
      "7400 0.693147 [[ 0.00051738]\n",
      " [-0.00051723]]\n",
      "Accuracy: 0.25\n",
      "7600 0.693147 [[ 0.00045654]\n",
      " [-0.00045646]]\n",
      "Accuracy: 0.25\n",
      "7800 0.693147 [[ 0.00040289]\n",
      " [-0.00040281]]\n",
      "Accuracy: 0.25\n",
      "8000 0.693147 [[ 0.00035554]\n",
      " [-0.00035546]]\n",
      "Accuracy: 0.25\n",
      "8200 0.693147 [[ 0.00031376]\n",
      " [-0.00031368]]\n",
      "Accuracy: 0.25\n",
      "8400 0.693147 [[ 0.00027689]\n",
      " [-0.00027681]]\n",
      "Accuracy: 0.25\n",
      "8600 0.693147 [[ 0.00024436]\n",
      " [-0.00024427]]\n",
      "Accuracy: 0.25\n",
      "8800 0.693147 [[ 0.00021563]\n",
      " [-0.00021556]]\n",
      "Accuracy: 0.25\n",
      "9000 0.693147 [[ 0.00019029]\n",
      " [-0.00019022]]\n",
      "Accuracy: 0.25\n",
      "9200 0.693147 [[ 0.00016792]\n",
      " [-0.00016786]]\n",
      "Accuracy: 0.25\n",
      "9400 0.693147 [[ 0.00014818]\n",
      " [-0.00014813]]\n",
      "Accuracy: 0.25\n",
      "9600 0.693147 [[ 0.00013076]\n",
      " [-0.00013071]]\n",
      "Accuracy: 0.25\n",
      "9800 0.693147 [[ 0.00011539]\n",
      " [-0.00011535]]\n",
      "[array([[ 0.5       ],\n",
      "       [ 0.49997455],\n",
      "       [ 0.50002551],\n",
      "       [ 0.5       ]], dtype=float32), array([[ 1.],\n",
      "       [ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.]], dtype=float32), array([[False],\n",
      "       [False],\n",
      "       [ True],\n",
      "       [False]], dtype=bool), 0.25]\n",
      "Accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_data = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[4,2], name=\"x-input\")\n",
    "Y = tf.placeholder(tf.float32, shape=[4,1], name=\"y-input\")\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0))\n",
    "\n",
    "# hypothesis\n",
    "h = tf.matmul(X, W)\n",
    "hypothesis = tf.div(1., 1.+tf.exp(-h))\n",
    "#hypothesis = tf.sigmoid(tf.matmul(X, W))\n",
    "\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.01) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    \n",
    "    # Fit the line.\n",
    "    for step in range(10000):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            accuracy_val = accuracy.eval({X:x_data, Y:y_data})\n",
    "            print(\"Accuracy:\", accuracy_val)\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron으로 XOR구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "0 0.733014 W1 [[ 0.47215295 -0.69309139]\n",
      " [ 0.24930049 -0.53286612]] W2 [[ 0.28796157]\n",
      " [ 0.3299177 ]]\n",
      "Accuracy: 0.5\n",
      "500 0.694023 W1 [[ 0.48714459 -0.71728677]\n",
      " [ 0.24278042 -0.56543088]] W2 [[-0.72024435]\n",
      " [-0.4035407 ]]\n",
      "Accuracy: 0.5\n",
      "1000 0.693487 W1 [[ 0.4895283  -0.75421178]\n",
      " [ 0.21315995 -0.61835235]] W2 [[-0.87626064]\n",
      " [-0.55592251]]\n",
      "Accuracy: 0.5\n",
      "1500 0.693312 W1 [[ 0.49425572 -0.79633206]\n",
      " [ 0.1824806  -0.67781311]] W2 [[-0.9608531 ]\n",
      " [-0.65095031]]\n",
      "Accuracy: 0.5\n",
      "2000 0.693214 W1 [[ 0.50394738 -0.84290397]\n",
      " [ 0.15266833 -0.74301791]] W2 [[-1.01804209]\n",
      " [-0.72456574]]\n",
      "Accuracy: 0.5\n",
      "2500 0.693138 W1 [[ 0.51905942 -0.89447898]\n",
      " [ 0.12317244 -0.81463188]] W2 [[-1.06011093]\n",
      " [-0.78869474]]\n",
      "Accuracy: 0.5\n",
      "3000 0.693067 W1 [[ 0.53987592 -0.9519397 ]\n",
      " [ 0.09307891 -0.89366746]] W2 [[-1.09191132]\n",
      " [-0.84946865]]\n",
      "Accuracy: 0.5\n",
      "3500 0.69299 W1 [[ 0.56687897 -1.01638985]\n",
      " [ 0.06138476 -0.9813807 ]] W2 [[-1.11559188]\n",
      " [-0.9110899 ]]\n",
      "Accuracy: 0.5\n",
      "4000 0.692896 W1 [[ 0.60091496 -1.08922207]\n",
      " [ 0.02700887 -1.0793699 ]] W2 [[-1.13203716]\n",
      " [-0.9771899 ]]\n",
      "Accuracy: 0.5\n",
      "4500 0.692774 W1 [[ 0.64339799 -1.17233157]\n",
      " [-0.01125724 -1.18982875]] W2 [[-1.14141321]\n",
      " [-1.05158842]]\n",
      "Accuracy: 0.5\n",
      "5000 0.692603 W1 [[ 0.69667166 -1.26852715]\n",
      " [-0.05482419 -1.31602836]] W2 [[-1.14341903]\n",
      " [-1.13903224]]\n",
      "Accuracy: 0.5\n",
      "5500 0.692341 W1 [[ 0.76472926 -1.38238025]\n",
      " [-0.10539752 -1.4632585 ]] W2 [[-1.13747633]\n",
      " [-1.24637222]]\n",
      "Accuracy: 0.5\n",
      "6000 0.691903 W1 [[ 0.85482454 -1.52207649]\n",
      " [-0.16506554 -1.64082038]] W2 [[-1.12317717]\n",
      " [-1.38503456]]\n",
      "Accuracy: 0.5\n",
      "6500 0.691061 W1 [[ 0.98156536 -1.70393419]\n",
      " [-0.23626573 -1.86665845]] W2 [[-1.10223317]\n",
      " [-1.5770787 ]]\n",
      "Accuracy: 0.5\n",
      "7000 0.689119 W1 [[ 1.17902219 -1.96451092]\n",
      " [-0.32137755 -2.17892241]] W2 [[-1.08889425]\n",
      " [-1.87189257]]\n",
      "Accuracy: 0.5\n",
      "7500 0.683652 W1 [[ 1.53877366 -2.38815999]\n",
      " [-0.42670915 -2.65817142]] W2 [[-1.1670779 ]\n",
      " [-2.38505507]]\n",
      "Accuracy: 0.5\n",
      "8000 0.668385 W1 [[ 2.27503586 -3.07854462]\n",
      " [-0.63497174 -3.38025045]] W2 [[-1.65269637]\n",
      " [-3.25375128]]\n",
      "Accuracy: 0.75\n",
      "8500 0.642 W1 [[ 3.47419047 -3.85443997]\n",
      " [-1.1697588  -4.12360382]] W2 [[-2.85055852]\n",
      " [-4.22717333]]\n",
      "Accuracy: 0.75\n",
      "9000 0.621402 W1 [[ 4.54066467 -4.39078951]\n",
      " [-1.83612299 -4.59719419]] W2 [[-4.19257069]\n",
      " [-4.88743544]]\n",
      "Accuracy: 0.75\n",
      "9500 0.611743 W1 [[ 5.21598625 -4.71507359]\n",
      " [-2.33127618 -4.85929537]] W2 [[-5.18308496]\n",
      " [-5.26376534]]\n",
      "Accuracy: 0.75\n",
      "10000 0.607208 W1 [[ 5.65583944 -4.92964506]\n",
      " [-2.67192936 -5.01798391]] W2 [[-5.88493395]\n",
      " [-5.49395704]]\n",
      "Accuracy: 0.75\n",
      "10500 0.604774 W1 [[ 5.96897221 -5.08553028]\n",
      " [-2.91783595 -5.12502241]] W2 [[-6.40912485]\n",
      " [-5.65021372]]\n",
      "Accuracy: 0.75\n",
      "11000 0.603307 W1 [[ 6.20776653 -5.20644283]\n",
      " [-3.10525823 -5.20324135]] W2 [[-6.8212409 ]\n",
      " [-5.76511145]]\n",
      "Accuracy: 0.75\n",
      "11500 0.602343 W1 [[ 6.39893436 -5.30458164]\n",
      " [-3.25443888 -5.26372766]] W2 [[-7.15825367]\n",
      " [-5.85454464]]\n",
      "Accuracy: 0.75\n",
      "12000 0.601668 W1 [[ 6.55742025 -5.38687086]\n",
      " [-3.37718081 -5.31245136]] W2 [[-7.44211292]\n",
      " [-5.9270668 ]]\n",
      "Accuracy: 0.75\n",
      "12500 0.601173 W1 [[ 6.69227934 -5.45756006]\n",
      " [-3.48078227 -5.352911  ]] W2 [[-7.6866622 ]\n",
      " [-5.98768806]]\n",
      "Accuracy: 0.75\n",
      "13000 0.600795 W1 [[ 6.80934286 -5.51942396]\n",
      " [-3.57000113 -5.38730526]] W2 [[-7.9010973 ]\n",
      " [-6.03955221]]\n",
      "Accuracy: 0.75\n",
      "13500 0.600498 W1 [[ 6.91257    -5.57437086]\n",
      " [-3.64807606 -5.41708422]] W2 [[-8.09179688]\n",
      " [-6.0847373 ]]\n",
      "Accuracy: 0.75\n",
      "14000 0.60026 W1 [[ 7.0047617  -5.62375498]\n",
      " [-3.71730089 -5.44325399]] W2 [[-8.26333427]\n",
      " [-6.1246829 ]]\n",
      "Accuracy: 0.75\n",
      "14500 0.600064 W1 [[ 7.08796072 -5.66857862]\n",
      " [-3.77934694 -5.46653414]] W2 [[-8.41911793]\n",
      " [-6.16042233]]\n",
      "Accuracy: 0.75\n",
      "15000 0.599901 W1 [[ 7.16370106 -5.70959282]\n",
      " [-3.83547187 -5.48745441]] W2 [[-8.56172085]\n",
      " [-6.1927166 ]]\n",
      "Accuracy: 0.75\n",
      "15500 0.599762 W1 [[ 7.23316479 -5.74738884]\n",
      " [-3.88663363 -5.50641441]] W2 [[-8.69315243]\n",
      " [-6.22214317]]\n",
      "Accuracy: 0.75\n",
      "16000 0.599644 W1 [[ 7.29727364 -5.78242159]\n",
      " [-3.93358564 -5.52373457]] W2 [[-8.81499672]\n",
      " [-6.2491498 ]]\n",
      "Accuracy: 0.75\n",
      "16500 0.599542 W1 [[ 7.35676861 -5.81506586]\n",
      " [-3.97692561 -5.53964233]] W2 [[-8.92852402]\n",
      " [-6.27408743]]\n",
      "Accuracy: 0.75\n",
      "17000 0.599452 W1 [[ 7.41224575 -5.84561777]\n",
      " [-4.0171361  -5.5543499 ]] W2 [[-9.03478146]\n",
      " [-6.2972374 ]]\n",
      "Accuracy: 0.75\n",
      "17500 0.599374 W1 [[ 7.46419764 -5.87433052]\n",
      " [-4.05460835 -5.5680027 ]] W2 [[-9.13462543]\n",
      " [-6.31883335]]\n",
      "Accuracy: 0.75\n",
      "18000 0.599304 W1 [[ 7.51303005 -5.90141153]\n",
      " [-4.08967543 -5.58073997]] W2 [[-9.22877121]\n",
      " [-6.33905649]]\n",
      "Accuracy: 0.75\n",
      "18500 0.599241 W1 [[ 7.55908346 -5.92702961]\n",
      " [-4.12260056 -5.59266758]] W2 [[-9.31782436]\n",
      " [-6.35807562]]\n",
      "Accuracy: 0.75\n",
      "19000 0.599185 W1 [[ 7.60264826 -5.95133495]\n",
      " [-4.15362406 -5.60387039]] W2 [[-9.40230083]\n",
      " [-6.37600851]]\n",
      "Accuracy: 0.75\n",
      "19500 0.599135 W1 [[ 7.6439724  -5.9744544 ]\n",
      " [-4.18293476 -5.61442232]] W2 [[-9.48263645]\n",
      " [-6.39298058]]\n",
      "[array([[  8.69789103e-04],\n",
      "       [  9.91802514e-01],\n",
      "       [  1.42899770e-02],\n",
      "       [  1.61876846e-02]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [False],\n",
      "       [ True]], dtype=bool), 0.75]\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_data = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[4,2], name=\"x-input\")\n",
    "Y = tf.placeholder(tf.float32, shape=[4,1], name=\"y-input\")\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0), name=\"Weight1\")\n",
    "W2 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0), name=\"Weight2\")\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "\n",
    "# cost function\n",
    "#cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(hypothesis, Y))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.5) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    \n",
    "    # Fit the line.\n",
    "    for step in range(20000):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 500 == 0:\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            accuracy_val = accuracy.eval({X:x_data, Y:y_data})\n",
    "            print(\"Accuracy:\", accuracy_val)\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}),\"W1\", sess.run(W1),\"W2\", sess.run(W2))\n",
    "            \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
