{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 튜토리얼\n",
    "## 소개\n",
    "텐서플로우(TensorFlow)는 기계 학습과 딥러닝을 위해 구글에서 만든 오픈소스 라이브러리입니다. 데이터 플로우 그래프(Data Flow Graph) 방식을 사용하였습니다.\n",
    "\n",
    "### 데이터 플로우 그래프\n",
    "\n",
    "데이터 플로우 그래프는 수학 계산과 데이터의 흐름을 노드(Node)와 엣지(Edge)를 사용한 방향 그래프(Directed Graph)로 표현합니다.\n",
    "\n",
    "![data flow graph](https://www.tensorflow.org/images/tensors_flowing.gif)\n",
    "\n",
    "노드는 수학적 계산, 데이터 입/출력, 그리고 데이터의 읽기/저장 등의 작업을 수행합니다. 엣지는 노드들 간 데이터의 입출력 관계를 나타냅니다.\n",
    "\n",
    "엣지는 동적 사이즈의 다차원 데이터 배열(=텐서)을 실어나르는데, 여기에서 텐서플로우라는 이름이 지어졌습니다.\n",
    "\n",
    "> 텐서(Tensor)는 과학과 공학 등 다양한 분야에서 이전부터 쓰이던 개념입니다. 수학에서는 [임의의 기하 구조를 좌표 독립적으로 표현](http://ghebook.blogspot.kr/2011/06/tensor.html)하기 위한 표기법으로 알려져 있지만, 분야마다 조금씩 다른 의미로 사용됩니다. 여기에서는 *학습 데이터가 저장되는 다차원 배열* 정도로 이해하시면 되겠습니다.\n",
    "\n",
    "### 특징\n",
    "\n",
    "텐서플로우는 다음과 같은 특징을 가집니다:\n",
    "\n",
    "- 데이터 플로우 그래프를 통한 풍부한 표현력\n",
    "- 코드 수정 없이 CPU/GPU 모드로 동작\n",
    "- 아이디어 테스트에서 서비스 단계까지 이용 가능\n",
    "- 계산 구조와 목표 함수만 정의하면 자동으로 미분 계산을 처리 \n",
    "- Python/C++를 지원하며, [SWIG](http://www.swig.org)를 통해 다양한 언어 지원 가능\n",
    "\n",
    "*이후의 설명은 [Python](https://www.python.org)을 중심으로 진행하겠습니다.* (pip를 통한 Python3설치는 개발 중으로, Python2 기반으로 하겠습니다.)\n",
    "\n",
    "> *\"구글이 텐서플로우를 오픈소스로 한 것은, 기계 학습이 앞으로 제품과 기술을 혁신하는데 가장 필수적인 요소라고 믿기 때문입니다.\"      - Google Brain Team*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 개념 익히기\n",
    "\n",
    "일단 기본 용어부터 살펴보겠습니다.\n",
    "\n",
    "### 용어\n",
    "#### 오퍼레이션(Operation)\n",
    "그래프 상의 노드는 오퍼레이션(줄임말 *op*)으로 불립니다. 오퍼레이션은 하나 이상의 *텐서*를 받을 수 있습니다. 오퍼레이션은 계산을 수행하고, 결과를 하나 이상의 텐서로 반환할 수 있습니다.\n",
    "\n",
    "#### 텐서(Tensor)\n",
    "내부적으로 모든 데이터는 텐서를 통해 표현됩니다. 텐서는 일종의 다차원 배열인데, 그래프 내의 오퍼레이션 간에는 텐서만이 전달됩니다. ([Caffe](http://caffe.berkeleyvision.org)의 [Blob](http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html)과 유사합니다.)\n",
    "\n",
    "#### 세션(Session)\n",
    "\n",
    "그래프를 실행하기 위해서는 [세션](https://www.tensorflow.org/versions/master/api_docs/python/client.html#session-management) 객체가 필요합니다. 세션은 오퍼레이션의 실행 환경을 캡슐화한 것입니다.\n",
    "\n",
    "#### 변수(Variables)\n",
    "[변수](https://www.tensorflow.org/versions/master/how_tos/variables/index.html)는 그래프의 실행시, 패러미터를 저장하고 갱신하는데 사용됩니다. 메모리 상에서 텐서를 저장하는 버퍼 역할을 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-layer perceptron으로 XOR구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.798489 [[ 0.61553425]\n",
      " [ 0.92524439]]\n",
      "200 0.748683 [[ 0.41005871]\n",
      " [ 0.68686658]]\n",
      "400 0.721233 [[ 0.26119283]\n",
      " [ 0.50709534]]\n",
      "600 0.70708 [[ 0.15768373]\n",
      " [ 0.37541175]]\n",
      "800 0.700045 [[ 0.08781303]\n",
      " [ 0.28026974]]\n",
      "[array([[ 0.5       ],\n",
      "       [ 0.55281162],\n",
      "       [ 0.51048726],\n",
      "       [ 0.56315893]], dtype=float32), array([[ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.]], dtype=float32), array([[False],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [False]], dtype=bool), 0.5]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_data = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[4,2], name=\"x-input\")\n",
    "Y = tf.placeholder(tf.float32, shape=[4,1], name=\"y-input\")\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0))\n",
    "\n",
    "# hypothesis\n",
    "h = tf.matmul(X, W)\n",
    "hypothesis = tf.div(1., 1.+tf.exp(-h))\n",
    "#hypothesis = tf.sigmoid(tf.matmul(X, W))\n",
    "\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.01) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Fit the line.\n",
    "    for step in range(1000):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron으로 XOR구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.749469 W1 [[ 0.94492376  0.47230342]\n",
      " [ 0.78251195 -0.32605469]] W2 [[ 0.82486707]\n",
      " [ 0.45189855]]\n",
      "1000 0.693603 W1 [[ 0.89695239  0.53015965]\n",
      " [ 0.71336997 -0.33802629]] W2 [[-0.29987761]\n",
      " [-0.71628618]]\n",
      "2000 0.693309 W1 [[ 0.8590014   0.61026961]\n",
      " [ 0.63043636 -0.40766856]] W2 [[-0.31125689]\n",
      " [-0.92360377]]\n",
      "3000 0.693163 W1 [[ 0.83860743  0.7110492 ]\n",
      " [ 0.56337982 -0.51218098]] W2 [[-0.28926629]\n",
      " [-1.07920134]]\n",
      "4000 0.693014 W1 [[ 0.8294974   0.8471145 ]\n",
      " [ 0.5062573  -0.65339679]] W2 [[-0.24878846]\n",
      " [-1.2295239 ]]\n",
      "5000 0.69276 W1 [[ 0.82819396  1.04076862]\n",
      " [ 0.45715648 -0.85128617]] W2 [[-0.17833787]\n",
      " [-1.40279412]]\n",
      "6000 0.69204 W1 [[ 0.83083802  1.35159481]\n",
      " [ 0.42461067 -1.16522133]] W2 [[-0.03017333]\n",
      " [-1.65099072]]\n",
      "7000 0.684309 W1 [[ 0.80637026  2.15494728]\n",
      " [ 0.57383204 -1.90779757]] W2 [[ 0.55219746]\n",
      " [-2.32477593]]\n",
      "8000 0.616186 W1 [[ 0.82837915  4.54392958]\n",
      " [ 1.79427469 -3.79969645]] W2 [[ 2.24434996]\n",
      " [-6.0421629 ]]\n",
      "9000 0.60493 W1 [[ 0.98461968  5.37497854]\n",
      " [ 2.19400692 -4.49584436]] W2 [[ 2.81628346]\n",
      " [-7.86583233]]\n",
      "10000 0.60216 W1 [[ 1.10080528  5.7709198 ]\n",
      " [ 2.3829565  -4.81443167]] W2 [[ 3.10547161]\n",
      " [-8.81525326]]\n",
      "11000 0.600969 W1 [[ 1.19259763  6.02302599]\n",
      " [ 2.50330162 -5.01245022]] W2 [[ 3.29656601]\n",
      " [-9.44798946]]\n",
      "12000 0.600315 W1 [[ 1.26889074  6.20568657]\n",
      " [ 2.59050417 -5.15354204]] W2 [[ 3.43881798]\n",
      " [-9.92030716]]\n",
      "13000 0.599904 W1 [[ 1.33444345  6.34795046]\n",
      " [ 2.65838027 -5.26202869]] W2 [[  3.55200171]\n",
      " [-10.2962265 ]]\n",
      "14000 0.599624 W1 [[ 1.39207649  6.46397781]\n",
      " [ 2.71367908 -5.3495903 ]] W2 [[  3.64595056]\n",
      " [-10.60798359]]\n",
      "15000 0.59942 W1 [[ 1.44360518  6.56167889]\n",
      " [ 2.7601738  -5.42266846]] W2 [[  3.72624993]\n",
      " [-10.87404346]]\n",
      "16000 0.599265 W1 [[ 1.49026835  6.6458931 ]\n",
      " [ 2.80018473 -5.4851737 ]] W2 [[  3.79636574]\n",
      " [-11.1059227 ]]\n",
      "17000 0.599144 W1 [[ 1.53295457  6.71979189]\n",
      " [ 2.83522892 -5.5396452 ]] W2 [[  3.85859609]\n",
      " [-11.31131363]]\n",
      "18000 0.599047 W1 [[ 1.57232177  6.78556108]\n",
      " [ 2.86635995 -5.58782196]] W2 [[  3.91454101]\n",
      " [-11.49555969]]\n",
      "19000 0.598967 W1 [[ 1.60887468  6.84475565]\n",
      " [ 2.89432669 -5.63093662]] W2 [[  3.96536016]\n",
      " [-11.66255951]]\n",
      "[array([[ 0.00102648],\n",
      "       [ 0.99410206],\n",
      "       [ 0.00139046],\n",
      "       [ 0.00298265]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [False],\n",
      "       [ True]], dtype=bool), 0.75]\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_data = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[4,2], name=\"x-input\")\n",
    "Y = tf.placeholder(tf.float32, shape=[4,1], name=\"y-input\")\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0), name=\"Weight1\")\n",
    "W2 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0), name=\"Weight2\")\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "\n",
    "# cost function\n",
    "#cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(hypothesis, Y))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.5) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Fit the line.\n",
    "    for step in range(20000):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}),\"W1\", sess.run(W1),\"W2\", sess.run(W2))\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
